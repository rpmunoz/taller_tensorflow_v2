{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2-B5UZxUchfd"
   },
   "source": [
    "# Análisis de MNIST con tf.keras, tf.data y eager execution\n",
    "\n",
    "**Profesor:** Roberto Muñoz <br />\n",
    "**E-mail:** <rmunoz@metricarts.com> <br />\n",
    "\n",
    "**Colaborador:** Sebastián Arpón <br />\n",
    "**E-mail:** <rmunoz@metricarts.com> <br />\n",
    "\n",
    "En este laboratorio crearemos una red neuronal que pueda detectar a que digito corresponde una imagen que recibe (note que cada imagen contendra solo un digito). Utilizaremos la API `tf.data` [Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) la cual es muy eficiente e incluye funcionalidades como el shuffling y batching. \n",
    "\n",
    "El conjunto de datos con el que trabajaremos es el MINST el cual, como veremos mas adelante esta incluido en KERAS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "902Rjd5DZroO"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Activando Eager\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usamos la API de keras para descargar el dataset de MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "evWlYUkYefG8"
   },
   "outputs": [],
   "source": [
    "# obteniendo la data\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño train dataset:  60000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Tamaño train dataset: \", len(train_labels))\n",
    "\n",
    "np.unique(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño test dataset:  10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Tamaño test dataset: \", len(test_labels))\n",
    "\n",
    "np.unique(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisamos el tamaño de train_images y train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images\n",
      "Tipo:  <class 'numpy.ndarray'>\n",
      "Nº de elementos:  60000\n",
      "Dimensiones:  (60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train images\")\n",
    "print(\"Tipo: \", type(train_images))\n",
    "print(\"Nº de elementos: \", len(train_images))\n",
    "print(\"Dimensiones: \", train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels\n",
      "Tipo:  <class 'numpy.ndarray'>\n",
      "Nº de elementos:  60000\n",
      "Dimensiones:  (60000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train labels\")\n",
    "print(\"Tipo: \", type(train_labels))\n",
    "print(\"Nº de elementos: \", len(train_labels))\n",
    "print(\"Dimensiones: \", train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10d5bb0b8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1823935710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images[4,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisamos un par de imágenes del dataset train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indice del registro:  54596\n",
      "Label:  8\n",
      "Tamaño en pixels:  (28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x18229403c8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1823508780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i=np.random.randint(len(train_images))\n",
    "\n",
    "print(\"Indice del registro: \", i)\n",
    "print(\"Label: \", train_labels[i])\n",
    "print(\"Tamaño en pixels: \", train_images[i].shape)\n",
    "plt.imshow(train_images[i,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformamos train_images y test_images\n",
    "\n",
    "Transformamos train_images y test_images de matrices de 28x28 a un vector de largo 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "JA3braIeeggc"
   },
   "outputs": [],
   "source": [
    "# Chequeando el tamaño de los conjuntos de entrenamiento y test\n",
    "TRAINING_SIZE = len(train_images)\n",
    "TEST_SIZE = len(test_images)\n",
    "\n",
    "# transformando desde (N, 28, 28) a (N, 784)\n",
    "train_images = np.reshape(train_images, (TRAINING_SIZE, 784))\n",
    "test_images = np.reshape(test_images, (TEST_SIZE, 784))\n",
    "\n",
    "# Transformando cada arreglo desde uint8 a float32\n",
    "train_images = train_images.astype(np.float32)\n",
    "test_images = test_images.astype(np.float32)\n",
    "\n",
    "# Convirtiendo cada valor desde [0,255] a [0,1] \n",
    "train_images /= 255\n",
    "test_images /=  255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images\n",
      "60000\n",
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train images\")\n",
    "print(len(train_images))\n",
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test images\n",
      "10000\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(\"Test images\")\n",
    "print(len(test_images))\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformamos las etiquetas en un vector \n",
    "\n",
    "Usamos la función **tf.keras.utils.to_categorical** del módulo **tf.keras** para transformar cada valor de etiqueta a un vector conformato categórico.\n",
    "\n",
    "En el caso de usar la función de costo **categorical_crossentropy**, las etiquetas deben ser transformadas en formato categórico. Si tenemos 10 clases, entonces cada etiqueta debe ser transformado en un vector de largo 10 donde **todos los valores son cero** excepto el índice correspondiente a la clase el cual tendrá el **valor uno**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'train_labels_ORIG' not in locals():\n",
    "    train_labels_ORIG=train_labels.copy()\n",
    "    \n",
    "if 'test_labels_ORIG' not in locals():\n",
    "    test_labels_ORIG=test_labels.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "wbwRqi0BeicT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previo al cambio de formato\t:  5\n",
      "Posterior al cambio de formato\t:  [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "NUM_DIGITS = 10\n",
    "\n",
    "train_labels  = tf.keras.utils.to_categorical(train_labels_ORIG, NUM_DIGITS)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels_ORIG, NUM_DIGITS)\n",
    "\n",
    "print(\"Previo al cambio de formato\\t: \", train_labels_ORIG[0]) # The format of the labels before conversion\n",
    "print(\"Posterior al cambio de formato\\t: \", train_labels[0]) # The format of the labels after conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(type(train_labels))\n",
    "print(train_labels.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = train_labels.astype(np.float32)\n",
    "test_labels = test_labels.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "print(type(train_labels))\n",
    "print(train_labels.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definimos la arquitectura de la red neuronal con Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "jjNr3gr3ejh2"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(300, activation=tf.nn.relu, input_shape=(784,)))\n",
    "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definimos el optimizador que usaremos\n",
    "\n",
    "Esto es obligatorio mientras usamos eager execution\n",
    "\n",
    "Usaremos el optimizador RMS Propagation\n",
    "\n",
    "Más info en https://www.tensorflow.org/api_guides/python/train#Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=0.001)\n",
    "#optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elegimos la función de costo y compilamos el modelo\n",
    "\n",
    "Usaremos la función de costo categorical_crossentropy\n",
    "\n",
    "Más info de losses en https://www.tensorflow.org/api_docs/python/tf/keras/losses\n",
    "\n",
    "Más info de metrics en https://www.tensorflow.org/api_docs/python/tf/keras/metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                3010      \n",
      "=================================================================\n",
      "Total params: 238,510\n",
      "Trainable params: 238,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zUZPvDQYe5Xu"
   },
   "source": [
    "## 1. Entrenamos el modelo usando tf.data y train_on_batch()\n",
    "\n",
    "### Paso 1 - Creamos un dataset del tipo tf.data\n",
    "\n",
    "Ahora usaremos `tf.data.Dataset` [API](https://www.tensorflow.org/api_docs/python/tf/data) para convertir los arreglos de Numpy en un dataset de TensorFlow\n",
    "\n",
    "A continuacion crearemos un ciclo **for** que servira como una introduccion en la creacion de ciclos de entrenamientos personalizados. Aunque esencialmente estos ciclos hacer lo mismo que `model.fit`, esto nos permite personalizar todo el proceso y recolectar distintas metricas.\n",
    "\n",
    "Usamos un batch size de 128 elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "sdBd2pd_fdue"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=128\n",
    "\n",
    "# Dado que tf.data puede funcionar en colecciones de datos potencialmente grandes\n",
    "# La desordenaremos por partes.\n",
    "SHUFFLE_SIZE = 10000 \n",
    "\n",
    "# Creando el dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "dataset = dataset.shuffle(SHUFFLE_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ksAR-C6xgUu4"
   },
   "source": [
    "### Step 2 - Definimos las epocas de entrenamiento y entrenamos\n",
    "\n",
    "Aca entrenaremos sobre el dataset usando los distintos batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "kNgnUKPvgSCz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1\t Loss: 0.167212\tAccuracy: 0.958333\n",
      "Epoch #2\t Loss: 0.071764\tAccuracy: 0.979167\n",
      "Epoch #3\t Loss: 0.081332\tAccuracy: 0.968750\n",
      "Epoch #4\t Loss: 0.013837\tAccuracy: 1.000000\n",
      "Epoch #5\t Loss: 0.054777\tAccuracy: 0.968750\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for images, labels in dataset:\n",
    "        train_loss, train_accuracy = model.train_on_batch(images, labels)\n",
    "  \n",
    "  # Obtenemos cualquier metrica o ajustamos los parametros de entrenamiento\n",
    "    print('Epoch #%d\\t Loss: %.6f\\tAccuracy: %.6f' % (epoch + 1, train_loss, train_accuracy))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "tg5U3Iqkgo3J"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 104us/step\n",
      "Test accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy: %.2f' % (accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2. Entrenamos el modelo usando fit()\n",
    "\n",
    "### Paso 1 - Creamos una función que define el modelo\n",
    "\n",
    "Usaremos **sparse_categorical_crossentropy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Returns a short sequential model\n",
    "def create_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(512, activation=tf.nn.relu, input_shape=(784,)))\n",
    "    model.add(tf.keras.layers.Dropout(0.2))\n",
    "    model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n",
    "  \n",
    "    model.compile(optimizer=tf.train.AdamOptimizer(),\n",
    "                  loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "                  metrics=['accuracy'])\n",
    "  \n",
    "    return model\n",
    "\n",
    "\n",
    "# Create a basic model instance\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 2 - Entrenamos el modelo usando fit()\n",
    "\n",
    "Dado que usaremos la función de costo **tf.keras.losses.sparse_categorical_crossentropy**, las etiquetas deben ser valores simples y no vectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = train_labels_ORIG.copy()\n",
    "test_labels = test_labels_ORIG.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPOCHS=5\n",
    "checkpoint_dir = \"results\"\n",
    "\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.mkdir(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "59968/60000 [============================>.] - ETA: 0s - loss: 0.2213 - acc: 0.9343\n",
      "Epoch 00001: saving model to results/model_mnist_0001.ckpt\n",
      "60000/60000 [==============================] - 28s 464us/step - loss: 0.2212 - acc: 0.9344 - val_loss: 0.1025 - val_acc: 0.9670\n",
      "Epoch 2/5\n",
      "59968/60000 [============================>.] - ETA: 0s - loss: 0.0958 - acc: 0.9710\n",
      "Epoch 00002: saving model to results/model_mnist_0002.ckpt\n",
      "60000/60000 [==============================] - 30s 506us/step - loss: 0.0957 - acc: 0.9710 - val_loss: 0.0828 - val_acc: 0.9728\n",
      "Epoch 3/5\n",
      "59872/60000 [============================>.] - ETA: 0s - loss: 0.0677 - acc: 0.9788\n",
      "Epoch 00003: saving model to results/model_mnist_0003.ckpt\n",
      "60000/60000 [==============================] - 30s 501us/step - loss: 0.0677 - acc: 0.9788 - val_loss: 0.0735 - val_acc: 0.9767\n",
      "Epoch 4/5\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0530 - acc: 0.9829\n",
      "Epoch 00004: saving model to results/model_mnist_0004.ckpt\n",
      "60000/60000 [==============================] - 30s 507us/step - loss: 0.0529 - acc: 0.9829 - val_loss: 0.0648 - val_acc: 0.9807\n",
      "Epoch 5/5\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0417 - acc: 0.9860\n",
      "Epoch 00005: saving model to results/model_mnist_0005.ckpt\n",
      "60000/60000 [==============================] - 31s 514us/step - loss: 0.0418 - acc: 0.9860 - val_loss: 0.0656 - val_acc: 0.9819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x1821883c50>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = os.path.join(checkpoint_dir, \"model_mnist_{epoch:04d}.ckpt\")\n",
    "\n",
    "# Create checkpoint callback\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "                checkpoint_path, verbose=1, save_weights_only=True,\n",
    "                # Save weights, every 1-epochs\n",
    "                period=1)\n",
    "                                                 \n",
    "\n",
    "model = create_model()\n",
    "\n",
    "model.fit(train_images, train_labels,  epochs = EPOCHS, \n",
    "          validation_data = (test_images, test_labels),\n",
    "          callbacks = [cp_callback])  # pass callback to training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluamos el modelo recién entrenado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 174us/step\n",
      "Model accuracy: 98.19%\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(test_images, test_labels)\n",
    "\n",
    "print(\"Model accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restauramos una época del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/model_mnist_0001.ckpt\n",
      "results/model_mnist_0002.ckpt\n",
      "results/model_mnist_0003.ckpt\n",
      "results/model_mnist_0004.ckpt\n",
      "results/model_mnist_0005.ckpt\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "pattern = os.path.join(checkpoint_dir, \"*.ckpt\")\n",
    "checkpoints = sorted(glob.glob(pattern))\n",
    "\n",
    "for file in checkpoints:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 138us/step\n",
      "Restored model - accuracy: 96.70%\n"
     ]
    }
   ],
   "source": [
    "weight_file = 'results/model_mnist_0001.ckpt'\n",
    "\n",
    "model = create_model()\n",
    "model.load_weights(weight_file)\n",
    "loss, acc = model.evaluate(test_images, test_labels)\n",
    "\n",
    "print(\"Restored model - accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "2-mnist-with-keras-eager-and-tf-data.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
